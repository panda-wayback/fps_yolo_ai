#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MPSæµ‹è¯•è„šæœ¬
éªŒè¯macOSçš„MPSåŠ é€Ÿæ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import torch
import time
import numpy as np
from ultralytics import YOLO


def test_mps_availability():
    """æµ‹è¯•MPSå¯ç”¨æ€§"""
    print("=== MPSå¯ç”¨æ€§æµ‹è¯• ===")
    
    # æ£€æŸ¥MPSæ˜¯å¦å¯ç”¨
    mps_available = torch.backends.mps.is_available()
    print(f"MPSå¯ç”¨: {'âœ… æ˜¯' if mps_available else 'âŒ å¦'}")
    
    if not mps_available:
        print("âŒ MPSä¸å¯ç”¨ï¼Œå¯èƒ½çš„åŸå› :")
        print("  1. macOSç‰ˆæœ¬è¿‡ä½ï¼ˆéœ€è¦macOS 12.3+ï¼‰")
        print("  2. PyTorchç‰ˆæœ¬è¿‡ä½ï¼ˆéœ€è¦1.12+ï¼‰")
        print("  3. æ²¡æœ‰Apple SiliconèŠ¯ç‰‡")
        return False
    
    # æ£€æŸ¥MPSæ˜¯å¦å·²æ„å»º
    mps_built = torch.backends.mps.is_built()
    print(f"MPSå·²æ„å»º: {'âœ… æ˜¯' if mps_built else 'âŒ å¦'}")
    
    return True


def test_mps_performance():
    """æµ‹è¯•MPSæ€§èƒ½"""
    print("\n=== MPSæ€§èƒ½æµ‹è¯• ===")
    
    if not torch.backends.mps.is_available():
        print("âŒ MPSä¸å¯ç”¨ï¼Œè·³è¿‡æ€§èƒ½æµ‹è¯•")
        return
    
    # åˆ›å»ºæµ‹è¯•å¼ é‡
    size = (1000, 1000)
    
    # CPUæµ‹è¯•
    print("CPUæ€§èƒ½æµ‹è¯•...")
    cpu_tensor = torch.randn(size)
    
    start_time = time.time()
    for _ in range(100):
        result = torch.matmul(cpu_tensor, cpu_tensor)
    cpu_time = time.time() - start_time
    print(f"CPUæ—¶é—´: {cpu_time:.3f}ç§’")
    
    # MPSæµ‹è¯•
    print("MPSæ€§èƒ½æµ‹è¯•...")
    mps_tensor = torch.randn(size, device='mps')
    
    start_time = time.time()
    for _ in range(100):
        result = torch.matmul(mps_tensor, mps_tensor)
    mps_time = time.time() - start_time
    print(f"MPSæ—¶é—´: {mps_time:.3f}ç§’")
    
    # æ€§èƒ½æ¯”è¾ƒ
    speedup = cpu_time / mps_time
    print(f"åŠ é€Ÿæ¯”: {speedup:.2f}x")
    
    if speedup > 1:
        print("âœ… MPSåŠ é€Ÿæœ‰æ•ˆ")
    else:
        print("âš ï¸  MPSåŠ é€Ÿæ•ˆæœä¸æ˜æ˜¾")


def test_yolo_with_mps():
    """æµ‹è¯•YOLOæ¨¡å‹åœ¨MPSä¸Šçš„è¿è¡Œ"""
    print("\n=== YOLO MPSæµ‹è¯• ===")
    
    if not torch.backends.mps.is_available():
        print("âŒ MPSä¸å¯ç”¨ï¼Œè·³è¿‡YOLOæµ‹è¯•")
        return
    
    try:
        # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        print("åŠ è½½YOLOæ¨¡å‹...")
        model = YOLO('yolov8n.pt')  # ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹è¿›è¡Œæµ‹è¯•
        
        # ç§»åŠ¨åˆ°MPSè®¾å¤‡
        model.to('mps')
        print("æ¨¡å‹å·²ç§»åŠ¨åˆ°MPSè®¾å¤‡")
        
        # åˆ›å»ºæµ‹è¯•å›¾åƒ
        test_img = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)
        
        # é¢„çƒ­
        print("é¢„çƒ­æ¨¡å‹...")
        for _ in range(3):
            _ = model(test_img, verbose=False)
        
        # æµ‹è¯•æ¨ç†æ—¶é—´
        print("æµ‹è¯•æ¨ç†æ€§èƒ½...")
        start_time = time.time()
        for _ in range(10):
            results = model(test_img, verbose=False)
        end_time = time.time()
        
        avg_time = (end_time - start_time) / 10
        print(f"å¹³å‡æ¨ç†æ—¶é—´: {avg_time*1000:.1f} ms")
        print(f"æ¨ç†FPS: {1/avg_time:.1f}")
        
        print("âœ… YOLO MPSæµ‹è¯•æˆåŠŸ")
        
    except Exception as e:
        print(f"âŒ YOLO MPSæµ‹è¯•å¤±è´¥: {e}")
        print("å¯èƒ½çš„åŸå› :")
        print("  1. æ¨¡å‹ä¸æ”¯æŒMPS")
        print("  2. å†…å­˜ä¸è¶³")
        print("  3. MPSé©±åŠ¨é—®é¢˜")


def test_memory_usage():
    """æµ‹è¯•å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    print("\n=== å†…å­˜ä½¿ç”¨æµ‹è¯• ===")
    
    if not torch.backends.mps.is_available():
        print("âŒ MPSä¸å¯ç”¨ï¼Œè·³è¿‡å†…å­˜æµ‹è¯•")
        return
    
    try:
        # æ£€æŸ¥åˆå§‹å†…å­˜
        initial_memory = torch.mps.current_allocated_memory()
        print(f"åˆå§‹MPSå†…å­˜: {initial_memory / 1024**2:.1f} MB")
        
        # åˆ†é…ä¸€äº›å†…å­˜
        tensors = []
        for i in range(5):
            tensor = torch.randn(1000, 1000, device='mps')
            tensors.append(tensor)
            current_memory = torch.mps.current_allocated_memory()
            print(f"åˆ†é…å¼ é‡ {i+1}: {current_memory / 1024**2:.1f} MB")
        
        # é‡Šæ”¾å†…å­˜
        del tensors
        torch.mps.empty_cache()
        
        final_memory = torch.mps.current_allocated_memory()
        print(f"é‡Šæ”¾åMPSå†…å­˜: {final_memory / 1024**2:.1f} MB")
        
        print("âœ… å†…å­˜ç®¡ç†æ­£å¸¸")
        
    except Exception as e:
        print(f"âŒ å†…å­˜æµ‹è¯•å¤±è´¥: {e}")


if __name__ == "__main__":
    print("ğŸ§ª MPSæµ‹è¯•è„šæœ¬")
    print("=" * 40)
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    if test_mps_availability():
        test_mps_performance()
        test_yolo_with_mps()
        test_memory_usage()
    
    print("\næµ‹è¯•å®Œæˆï¼")

